{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import six\n",
    "def mat_to_data(path):\n",
    "    mat = loadmat(path)\n",
    "    names = mat['dataStruct'].dtype.names\n",
    "    ndata = {n: mat['dataStruct'][n][0, 0] for n in names}\n",
    "    for kk,vv in six.iteritems(ndata):\n",
    "#         print(vv.shape)\n",
    "        if vv.shape == (1,1):\n",
    "            ndata[kk] = vv[0,0]\n",
    "    return ndata\n",
    "\n",
    "def get_label(infile):\n",
    "    return infile.split(\".\")[-2][-1] == \"0\"\n",
    "\n",
    "def test_mat_to_data(path = \"./data/1_1_0.mat\"):\n",
    "    data = mat_to_data(path)\n",
    "    label = get_label(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_1_0.mat\n",
      "(1000, 16) True [1, 1]\n"
     ]
    }
   ],
   "source": [
    "def simplegen(folder):\n",
    "    \"\"\"I_J_K.mat - the Jth training data segment \n",
    "    for the Ith patient (there are three patients)\n",
    "    corresponding to the Kth class (K=0 for interictal, K=1 for preictal) .\"\"\"\n",
    "    infiles = list(filter(lambda x: x.endswith(\"mat\"), os.listdir(folder)))\n",
    "    NUM_FILES = len(infiles)\n",
    "    for nn, ff in enumerate(infiles):\n",
    "        print(ff)\n",
    "        ff = os.path.join(folder,ff)\n",
    "        meta = [int(k) for k in ff.split(\"/\")[-1].split(\".\")[0].split(\"_\")[:2]]\n",
    "        label = get_label(ff)\n",
    "        data = mat_to_data(ff)\n",
    "#         yield np.dstack(data[\"data\"]).transpose(0,2,1), np.array([[label]])\n",
    "        xx= (data[\"data\"])\n",
    "        piece_len=1000\n",
    "        batch_size = xx.shape[0]//piece_len\n",
    "        nchannels = xx.shape[1]\n",
    "        yy = np.array(label)\n",
    "        yield xx, yy, meta\n",
    "\n",
    "\n",
    "def filegenchop(folder, piece_len=1000):\n",
    "    gen = simplegen(folder)\n",
    "    for nn, (xbig, ybig, meta) in enumerate(gen):\n",
    "        piece_len=1000\n",
    "        batch_size = xbig.shape[0]//piece_len\n",
    "        nchannels = xbig.shape[1]\n",
    "        xbig = np.reshape(xbig, (batch_size, piece_len, nchannels))\n",
    "        for xx in xbig:\n",
    "            yield xx, ybig, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "def chop_into_database( datadir,\n",
    "        piece_len = 1000,\n",
    "        tablename = \"train1\",\n",
    "        ):\n",
    "    \n",
    "    dbname = \"%s_piece_%u.db\" % (tablename, piece_len)\n",
    "    print(\"SAVING TO \", dbname)\n",
    "    with sqlite3.connect(dbname) as conn:\n",
    "        curs = conn.cursor()\n",
    "\n",
    "        print(\"PURGING\")\n",
    "        qry = \"DROP TABLE IF EXISTS %s\" % tablename\n",
    "        curs.execute(qry)\n",
    "\n",
    "        print(\"CREATING\")\n",
    "        qry = \"\"\"CREATE TABLE IF NOT EXISTS train1(\n",
    "        id INT PRIMARY KEY,\n",
    "        label INT,\n",
    "        data BLOB,\n",
    "        individual INT,\n",
    "        segment INT\n",
    "        )\"\"\"\n",
    "\n",
    "        curs.execute(qry)\n",
    "\n",
    "        insert_qry = \"INSERT INTO %s (id, label, data, individual, segment) VALUES (?,?,?,?,?)\"  % tablename\n",
    "        gen = filegenchop(datadir, piece_len=piece_len)\n",
    "\n",
    "        print(\"CHOPPING AND INSERTING\")\n",
    "        for id_, (xx, yy, meta) in enumerate(gen):\n",
    "        #     print(xx.shape, yy, meta)\n",
    "            label = bool(yy)\n",
    "            blob = sqlite3.Binary(xx.tobytes())\n",
    "            curs.execute(insert_qry, (id_, label, blob, meta[0], meta[1]))\n",
    "    return dbname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING TO  train1_piece_1000.db\n",
      "CHOPPING AND INSERTING\n",
      "1_1_0.mat\n",
      "1_1_1.mat\n",
      "1_2_0.mat\n",
      "1_2_1.mat\n"
     ]
    }
   ],
   "source": [
    "tablename =  \"train1\"\n",
    "piece_len = 1000\n",
    "dbname = chop_into_database( datadir,\n",
    "        piece_len = piece_len,\n",
    "        tablename =tablename,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(960,)\n"
     ]
    }
   ],
   "source": [
    "with sqlite3.connect(dbname) as conn:\n",
    "    curs = conn.cursor()\n",
    "    curs.execute(\"SELECT COUNT(*) FROM %s\" % tablename)\n",
    "    print(curs.fetchone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reconstruct_from_sql(row, nchannels = 16):\n",
    "    row = list(row)\n",
    "    row[2] = np.fromstring(row[2], dtype=np.dtype('<f4'),).reshape(-1, nchannels)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_1_0.mat\n"
     ]
    }
   ],
   "source": [
    "\"TEST\"\n",
    "with sqlite3.connect(dbname) as conn:\n",
    "    curs = conn.cursor()\n",
    "    gen = filegenchop(datadir, piece_len=piece_len)\n",
    "    xx, yy, meta = next(gen)\n",
    "\n",
    "    curs.execute(\"SELECT * FROM %s\" % tablename)\n",
    "    out = reconstruct_from_sql(curs.fetchone())\n",
    "    xx_reconstr = out[2]\n",
    "\n",
    "    assert (xx_reconstr == xx).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "piece_len=1000\n",
    "batch_size = xx.shape[0]//piece_len\n",
    "nchannels = xx.shape[1]\n",
    "# np.reshape(xx, (batch_size, piece_len, nchannels)).shape\n",
    "# np.reshape(yy, (batch_size, piece_len)).shape\n",
    "yy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (np.reshape(xx, (batch_size, piece_len, nchannels))[1] == xx[1000:2000,:]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "240000/400 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#downsampled:\n",
    "120000 / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10*60/120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imdb example:\n",
    "\n",
    "    X (25000 , 80)\n",
    "      (num_samples, seq_len)\n",
    "     \n",
    "eeg:\n",
    "\n",
    "    X (num_samples, seq_len, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-cb51d7941c79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# this function returns the loss and grads given the input picture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0miterate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "input_ = mo.layers[0].input\n",
    "la = mo.layers[-1]\n",
    "\n",
    "# grads = K.gradients(K.mean(la.output), la.input)\n",
    "\n",
    "loss = K.mean(layer_output[:, filter_index, :, :])\n",
    "\n",
    "# normalization trick: we normalize the gradient\n",
    "# grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
    "\n",
    "# this function returns the loss and grads given the input picture\n",
    "iterate = K.function([input_], [loss, grads])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "theano.tensor.var.TensorVariable"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(la.input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_1_0.mat\n",
      "Epoch 1/300\n",
      "1_1_1.mat\n",
      "1_2_0.mat\n",
      "1_2_1.mat\n",
      "4/4 [==============================] - 16s - loss: 2.0971 - acc: 0.5000\n",
      "Epoch 2/300\n",
      "4/4 [==============================] - 14s - loss: 8.5893 - acc: 0.5000\n",
      "Epoch 3/300\n",
      "4/4 [==============================] - 14s - loss: 8.5872 - acc: 0.5000\n",
      "Epoch 4/300\n",
      "4/4 [==============================] - 14s - loss: 8.5830 - acc: 0.5000\n",
      "Epoch 5/300\n",
      "4/4 [==============================] - 13s - loss: 8.5778 - acc: 0.5000\n",
      "Epoch 6/300\n",
      "4/4 [==============================] - 14s - loss: 8.5709 - acc: 0.5000\n",
      "Epoch 7/300\n",
      "4/4 [==============================] - 16s - loss: 8.5632 - acc: 0.5000\n",
      "Epoch 8/300\n",
      "4/4 [==============================] - 12s - loss: 8.5544 - acc: 0.5000\n",
      "Epoch 9/300\n",
      "4/4 [==============================] - 17s - loss: 8.5451 - acc: 0.5000\n",
      "Epoch 10/300\n",
      "4/4 [==============================] - 15s - loss: 8.5356 - acc: 0.5000\n",
      "Epoch 11/300\n",
      "4/4 [==============================] - 12s - loss: 8.5260 - acc: 0.5000\n",
      "Epoch 12/300\n",
      "4/4 [==============================] - 14s - loss: 8.5153 - acc: 0.5000\n",
      "Epoch 13/300\n",
      "4/4 [==============================] - 14s - loss: 8.5040 - acc: 0.5000\n",
      "Epoch 14/300\n",
      "4/4 [==============================] - 15s - loss: 8.4922 - acc: 0.5000\n",
      "Epoch 15/300\n",
      "4/4 [==============================] - 17s - loss: 8.4802 - acc: 0.5000\n",
      "Epoch 16/300\n",
      "4/4 [==============================] - 15s - loss: 8.4679 - acc: 0.5000\n",
      "Epoch 17/300\n",
      "4/4 [==============================] - 14s - loss: 8.4553 - acc: 0.5000\n",
      "Epoch 18/300\n",
      "4/4 [==============================] - 14s - loss: 8.4420 - acc: 0.5000\n",
      "Epoch 19/300\n",
      "4/4 [==============================] - 16s - loss: 8.4288 - acc: 0.5000\n",
      "Epoch 20/300\n",
      "4/4 [==============================] - 15s - loss: 8.4164 - acc: 0.5000\n",
      "Epoch 21/300\n",
      "4/4 [==============================] - 15s - loss: 8.4037 - acc: 0.5000\n",
      "Epoch 22/300\n",
      "4/4 [==============================] - 12s - loss: 8.3969 - acc: 0.5000\n",
      "Epoch 23/300\n",
      "4/4 [==============================] - 13s - loss: 8.3896 - acc: 0.5000\n",
      "Epoch 24/300\n",
      "4/4 [==============================] - 16s - loss: 8.3818 - acc: 0.5000\n",
      "Epoch 25/300\n",
      "4/4 [==============================] - 12s - loss: 8.3737 - acc: 0.5000\n",
      "Epoch 26/300\n",
      "4/4 [==============================] - 12s - loss: 8.3655 - acc: 0.5000\n",
      "Epoch 27/300\n",
      "4/4 [==============================] - 11s - loss: 8.3572 - acc: 0.5000\n",
      "Epoch 28/300\n",
      "4/4 [==============================] - 15s - loss: 8.3489 - acc: 0.5000\n",
      "Epoch 29/300\n",
      "4/4 [==============================] - 14s - loss: 8.3406 - acc: 0.5000\n",
      "Epoch 30/300\n",
      "4/4 [==============================] - 14s - loss: 8.3323 - acc: 0.5000\n",
      "Epoch 31/300\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-94bd174c48ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m mo.fit_generator(gen, nb_worker=1,\n\u001b[1;32m      9\u001b[0m                  \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                  callbacks=[change_lr])\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, **kwargs)\u001b[0m\n\u001b[1;32m    880\u001b[0m                                         \u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_q_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m                                         pickle_safe=pickle_safe)\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m     def evaluate_generator(self, generator, val_samples,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[1;32m   1459\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1460\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1461\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1462\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m                     \u001b[0m_stop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1237\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    790\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/theano/gof/op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from itertools import cycle\n",
    "datadir = \"data/\"\n",
    "BATCH_SIZE = 4\n",
    "gen = cycle(filegen(datadir, BATCH_SIZE = BATCH_SIZE))\n",
    "# print(type(gen))\n",
    "# print(gen.next())\n",
    "\n",
    "mo.fit_generator(gen, nb_worker=1,\n",
    "                 nb_epoch=300, samples_per_epoch = BATCH_SIZE,\n",
    "                 callbacks=[change_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
