{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import six\n",
    "def mat_to_data(path):\n",
    "    mat = loadmat(path)\n",
    "    names = mat['dataStruct'].dtype.names\n",
    "    ndata = {n: mat['dataStruct'][n][0, 0] for n in names}\n",
    "    for kk,vv in six.iteritems(ndata):\n",
    "#         print(vv.shape)\n",
    "        if vv.shape == (1,1):\n",
    "            ndata[kk] = vv[0,0]\n",
    "    return ndata\n",
    "\n",
    "def get_label(infile):\n",
    "    return infile.split(\".\")[-2][-1] == \"0\"\n",
    "\n",
    "def test_mat_to_data(path = \"./data/1_1_0.mat\"):\n",
    "    data = mat_to_data(path)\n",
    "    label = get_label(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def simplegen(folder):\n",
    "    \"\"\"I_J_K.mat - the Jth training data segment \n",
    "    for the Ith patient (there are three patients)\n",
    "    corresponding to the Kth class (K=0 for interictal, K=1 for preictal) .\"\"\"\n",
    "    infiles = list(filter(lambda x: x.endswith(\"mat\"), os.listdir(folder)))\n",
    "    NUM_FILES = len(infiles)\n",
    "    for nn, ff in enumerate(infiles):\n",
    "        print(ff)\n",
    "        ff = os.path.join(folder,ff)\n",
    "        meta = [int(k) for k in ff.split(\"/\")[-1].split(\".\")[0].split(\"_\")[:2]]\n",
    "        label = get_label(ff)\n",
    "        data = mat_to_data(ff)\n",
    "#         yield np.dstack(data[\"data\"]).transpose(0,2,1), np.array([[label]])\n",
    "        xx= (data[\"data\"])\n",
    "        piece_len=1000\n",
    "        batch_size = xx.shape[0]//piece_len\n",
    "        nchannels = xx.shape[1]\n",
    "        yy = np.array(label)\n",
    "        yield xx, yy, meta\n",
    "\n",
    "\n",
    "def filegenchop(folder, piece_len=1000):\n",
    "    gen = simplegen(folder)\n",
    "    for nn, (xbig, ybig, meta) in enumerate(gen):\n",
    "        piece_len=1000\n",
    "        batch_size = xbig.shape[0]//piece_len\n",
    "        nchannels = xbig.shape[1]\n",
    "        xbig = np.reshape(xbig, (batch_size, piece_len, nchannels))\n",
    "        for xx in xbig:\n",
    "            yield xx, ybig, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_1_0.mat\n",
      "(1000, 16) True [1, 1]\n"
     ]
    }
   ],
   "source": [
    "datadir = \"data/\"\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "gen = simplegen(datadir)\n",
    "\n",
    "# gen = filegen(datadir, BATCH_SIZE = BATCH_SIZE)\n",
    "\n",
    "gen = filegenchop(datadir, piece_len=1000)\n",
    "\n",
    "for xx, yy, meta in gen:\n",
    "    print(xx.shape, yy, meta)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "def chop_into_database( datadir,\n",
    "        piece_len = 1000,\n",
    "        tablename = \"train1\",\n",
    "        ):\n",
    "    \n",
    "    dbname = \"%s_piece_%u.db\" % (tablename, piece_len)\n",
    "    print(\"SAVING TO \", dbname)\n",
    "    with sqlite3.connect(dbname) as conn:\n",
    "        curs = conn.cursor()\n",
    "\n",
    "        print(\"PURGING\")\n",
    "        qry = \"DROP TABLE IF EXISTS %s\" % tablename\n",
    "        curs.execute(qry)\n",
    "\n",
    "        print(\"CREATING\")\n",
    "        qry = \"\"\"CREATE TABLE IF NOT EXISTS train1(\n",
    "        id INT PRIMARY KEY,\n",
    "        label INT,\n",
    "        data BLOB,\n",
    "        individual INT,\n",
    "        segment INT\n",
    "        )\"\"\"\n",
    "\n",
    "        curs.execute(qry)\n",
    "\n",
    "        insert_qry = \"INSERT INTO %s (id, label, data, individual, segment) VALUES (?,?,?,?,?)\"  % tablename\n",
    "        gen = filegenchop(datadir, piece_len=piece_len)\n",
    "\n",
    "        print(\"CHOPPING AND INSERTING\")\n",
    "        for id_, (xx, yy, meta) in enumerate(gen):\n",
    "        #     print(xx.shape, yy, meta)\n",
    "            label = bool(yy)\n",
    "            blob = sqlite3.Binary(xx.tobytes())\n",
    "            curs.execute(insert_qry, (id_, label, blob, meta[0], meta[1]))\n",
    "    return dbname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVING TO  train1_piece_1000.db\n",
      "PURGING\n",
      "CREATING\n",
      "CHOPPING AND INSERTING\n",
      "1_1_0.mat\n",
      "1_1_1.mat\n",
      "1_2_0.mat\n",
      "1_2_1.mat\n"
     ]
    }
   ],
   "source": [
    "tablename =  \"train1\"\n",
    "piece_len = 1000\n",
    "dbname = chop_into_database( datadir,\n",
    "        piece_len = piece_len,\n",
    "        tablename =tablename,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(960,)\n"
     ]
    }
   ],
   "source": [
    "with sqlite3.connect(dbname) as conn:\n",
    "    curs = conn.cursor()\n",
    "    curs.execute(\"SELECT COUNT(*) FROM %s\" % tablename)\n",
    "    print(curs.fetchone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reconstruct_from_sql(row, nchannels = 16):\n",
    "    row = list(row)\n",
    "    row[2] = np.fromstring(row[2], dtype=np.dtype('<f4'),).reshape(-1, nchannels)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_1_0.mat\n"
     ]
    }
   ],
   "source": [
    "\"TEST\"\n",
    "with sqlite3.connect(dbname) as conn:\n",
    "    curs = conn.cursor()\n",
    "    gen = filegenchop(datadir, piece_len=piece_len)\n",
    "    xx, yy, meta = next(gen)\n",
    "\n",
    "    curs.execute(\"SELECT * FROM %s\" % tablename)\n",
    "    out = reconstruct_from_sql(curs.fetchone())\n",
    "    xx_reconstr = out[2]\n",
    "\n",
    "    assert (xx_reconstr == xx).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(740, 0)\n",
      "(771, 0)\n",
      "(364, 0)\n",
      "(763, 0)\n",
      "(473, 0)\n",
      "(23, 1)\n",
      "(267, 0)\n",
      "(911, 0)\n",
      "(4, 1)\n",
      "(336, 0)\n",
      "(833, 0)\n",
      "(932, 0)\n",
      "(672, 1)\n",
      "(616, 1)\n",
      "(523, 1)\n",
      "(773, 0)\n",
      "(262, 0)\n",
      "(575, 1)\n",
      "(590, 1)\n",
      "(737, 0)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "with sqlite3.connect(dbname) as conn:\n",
    "    curs = conn.cursor()\n",
    "#     select_qry = \"SELECT * FROM table WHERE id IN (SELECT id FROM %s ORDER BY RANDOM() LIMIT %u)\"\n",
    "#     select_qry = \"SELECT id FROM %s ORDER BY RANDOM() LIMIT %u\" % (tablename, batch_size)\n",
    "    select_qry = \"\"\"SELECT id,label INT, data, individual, segment\n",
    "                    FROM (SELECT abs(random() % (SELECT COUNT(id) FROM {0})) AS dummyid FROM {0} LIMIT {1}) AS t1\n",
    "                    INNER JOIN\n",
    "                    (SELECT * FROM {0}) AS t2\n",
    "                    ON dummyid = t2.id\"\"\".format(tablename, batch_size)\n",
    "    curs.execute(select_qry)\n",
    "#     print(len(curs.fetchmany(batch_size)))\n",
    "    print(*[(x[0], x[1]) for x in curs.fetchmany(batch_size)], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1000, 16)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_random_sqite_sample(dbname, tablename, batch_size = 20):\n",
    "    with sqlite3.connect(dbname) as conn:\n",
    "        curs = conn.cursor()\n",
    "        #select_qry = \"SELECT * FROM %s ORDER BY RANDOM() LIMIT %u\" % (tablename, batch_size)\n",
    "        select_qry = \"\"\"SELECT id,label INT, data, individual, segment\n",
    "                        FROM (SELECT abs(random() % (SELECT COUNT(id) FROM {0})) AS dummyid FROM {0} LIMIT {1}) AS t1\n",
    "                        INNER JOIN\n",
    "                        (SELECT * FROM {0}) AS t2\n",
    "                        ON dummyid = t2.id\"\"\".format(tablename, batch_size)\n",
    "        curs.execute(select_qry)\n",
    "        output_x = []\n",
    "        output_y = []\n",
    "        while True:\n",
    "            rows = curs.fetchmany(batch_size)\n",
    "            if not rows: break\n",
    "            for row in rows:\n",
    "                row = reconstruct_from_sql(row)\n",
    "                output_x.append(row[2])\n",
    "                output_y.append(row[1])\n",
    "        # dstack returns following dims: (seqlen=1000, nchannels=16, batch_size=20)\n",
    "        # we need (batch_size, seqlen, nchannels)\n",
    "        return np.dstack(output_x).transpose(2,0,1), np.array(output_y).ravel()\n",
    "    \n",
    "x_, y_ = get_random_sqite_sample(dbname, tablename, batch_size = 20)\n",
    "x_.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
